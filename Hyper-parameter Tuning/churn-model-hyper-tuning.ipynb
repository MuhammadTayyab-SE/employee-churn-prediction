{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from hyperopt import hp\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = pd.read_csv(\"./dataset.csv\")\n",
    "_target_column = \"Attrition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.drop(columns=[\"EmployeeNumber\"],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking nans\n",
    "employee_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking cloumns that contain single values\n",
    "single_valued_column = [column for column in employee_df.columns if len(employee_df[column].unique()) < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping single valued columns\n",
    "df = employee_df.drop(columns= single_valued_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_data_equally(df, target_column):\n",
    "    df = df.copy()\n",
    "    employee_attrition = df[df[target_column] == 1]\n",
    "    employee_non_attrition = df[df[target_column] != 1] \\\n",
    "                        .sample(n = len(employee_attrition))\n",
    "    df =  pd.concat([employee_attrition, employee_non_attrition])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 9   Gender                    1470 non-null   object\n",
      " 10  HourlyRate                1470 non-null   int64 \n",
      " 11  JobInvolvement            1470 non-null   int64 \n",
      " 12  JobLevel                  1470 non-null   int64 \n",
      " 13  JobRole                   1470 non-null   object\n",
      " 14  JobSatisfaction           1470 non-null   int64 \n",
      " 15  MaritalStatus             1470 non-null   object\n",
      " 16  MonthlyIncome             1470 non-null   int64 \n",
      " 17  MonthlyRate               1470 non-null   int64 \n",
      " 18  NumCompaniesWorked        1470 non-null   int64 \n",
      " 19  OverTime                  1470 non-null   object\n",
      " 20  PercentSalaryHike         1470 non-null   int64 \n",
      " 21  PerformanceRating         1470 non-null   int64 \n",
      " 22  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 23  StockOptionLevel          1470 non-null   int64 \n",
      " 24  TotalWorkingYears         1470 non-null   int64 \n",
      " 25  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 26  WorkLifeBalance           1470 non-null   int64 \n",
      " 27  YearsAtCompany            1470 non-null   int64 \n",
      " 28  YearsInCurrentRole        1470 non-null   int64 \n",
      " 29  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 30  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(23), object(8)\n",
      "memory usage: 356.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply label encoding to target column\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df[_target_column])\n",
    "df[_target_column] = label_encoder.transform(df[_target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature encoding\n",
    "object_cols = [col for col, dtype in df.dtypes.items() if dtype == \"object\" or dtype == \"string\"]\n",
    "feature_encoder = OrdinalEncoder()\n",
    "feature_encoder.fit(df[object_cols])\n",
    "df[object_cols] = feature_encoder.transform(df[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = distribute_data_equally(df, _target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "opacity": 1,
         "reversescale": false,
         "type": "heatmap",
         "x": [
          "Age",
          "Attrition",
          "BusinessTravel",
          "DailyRate",
          "Department",
          "DistanceFromHome",
          "Education",
          "EducationField",
          "EnvironmentSatisfaction",
          "Gender",
          "HourlyRate",
          "JobInvolvement",
          "JobLevel",
          "JobRole",
          "JobSatisfaction",
          "MaritalStatus",
          "MonthlyIncome",
          "MonthlyRate",
          "NumCompaniesWorked",
          "OverTime",
          "PercentSalaryHike",
          "PerformanceRating",
          "RelationshipSatisfaction",
          "StockOptionLevel",
          "TotalWorkingYears",
          "TrainingTimesLastYear",
          "WorkLifeBalance",
          "YearsAtCompany",
          "YearsInCurrentRole",
          "YearsSinceLastPromotion",
          "YearsWithCurrManager"
         ],
         "y": [
          "Age",
          "Attrition",
          "BusinessTravel",
          "DailyRate",
          "Department",
          "DistanceFromHome",
          "Education",
          "EducationField",
          "EnvironmentSatisfaction",
          "Gender",
          "HourlyRate",
          "JobInvolvement",
          "JobLevel",
          "JobRole",
          "JobSatisfaction",
          "MaritalStatus",
          "MonthlyIncome",
          "MonthlyRate",
          "NumCompaniesWorked",
          "OverTime",
          "PercentSalaryHike",
          "PerformanceRating",
          "RelationshipSatisfaction",
          "StockOptionLevel",
          "TotalWorkingYears",
          "TrainingTimesLastYear",
          "WorkLifeBalance",
          "YearsAtCompany",
          "YearsInCurrentRole",
          "YearsSinceLastPromotion",
          "YearsWithCurrManager"
         ],
         "z": [
          [
           1,
           -0.21188494080980172,
           0.03803551927658461,
           0.01870173943907148,
           -0.03806651717546608,
           -0.016469064720937936,
           0.2044419982891652,
           -0.0684602777783119,
           0.03777333891641263,
           0.008410390861334629,
           0.04537729655255323,
           0.022039749856737696,
           0.5322984512316848,
           -0.11752311959271518,
           0.04511002353614836,
           -0.1796546221127244,
           0.5230386923179968,
           -0.01189901969177255,
           0.2924628932163223,
           -0.03266906341267767,
           -0.00501198695271921,
           -0.016725290342173127,
           0.06578397552974694,
           0.10781438397348501,
           0.7021340905512334,
           -0.0485655975527119,
           -0.03742701591139105,
           0.36803256818109764,
           0.3006448161331995,
           0.2107948083228227,
           0.2402234444760164
          ],
          [
           -0.21188494080980172,
           1,
           0.03562632744356489,
           -0.07399913345611119,
           0.11715175357571722,
           0.04433116904442103,
           -0.0469140646953918,
           0.003045286684944241,
           -0.13454959227330665,
           0.043290448929478004,
           -0.05065797408870541,
           -0.16962191386981917,
           -0.232837481527023,
           0.08626330313866695,
           -0.142439159423648,
           0.23589109199350203,
           -0.24199396283578986,
           -0.0011713135674544062,
           0.05904631295517528,
           0.3123240133693072,
           0.021308386316823313,
           0.048751494941808644,
           -0.06815829906213401,
           -0.21833605451141255,
           -0.2332490387774205,
           -0.02004794966598787,
           -0.07883727744668335,
           -0.181406910198046,
           -0.24926103703267977,
           -0.04032779066765742,
           -0.21049137680688512
          ],
          [
           0.03803551927658461,
           0.03562632744356489,
           1,
           0.031128040725793865,
           0.04813652032609368,
           -0.06870642998948455,
           0.015570880761258492,
           0.028060074799952133,
           -0.04200371761639541,
           -0.009786465788189768,
           -0.03063419804995875,
           0.03783524187493622,
           0.014936329451371563,
           -0.00494677352876189,
           -0.01622021619690571,
           -0.014968621910563445,
           0.019375275256735807,
           0.0504525279898948,
           -0.0032244626029381417,
           0.0042709534102400165,
           -0.08163817373831926,
           -0.05210510166480561,
           0.007713571801843202,
           -0.004171316322419631,
           0.0757216517772843,
           -0.002543108826553894,
           -0.07647276881744339,
           0.031390250598443,
           0.0015768677678572667,
           -0.003949884492561511,
           0.009849971767811957
          ],
          [
           0.01870173943907148,
           -0.07399913345611119,
           0.031128040725793865,
           1,
           -0.026390840313729638,
           -0.06434958764064853,
           -0.03172780775432659,
           0.06306214651205079,
           0.041552659307872455,
           0.06987144182724432,
           0.056177158641713174,
           0.010510257411369451,
           -0.0029189596389754225,
           -0.01441525750125425,
           0.05424600463374355,
           -0.0825626698809224,
           -0.0017055486996842356,
           -0.09250082055470663,
           0.062102242598865834,
           -0.012739511447619237,
           0.03738990701893371,
           0.03556294073747078,
           0.005413137931607168,
           0.04212814745651885,
           0.011359357911573715,
           0.035564598985338806,
           0.01841228413300356,
           -0.046810228089188465,
           -0.019567712399833858,
           -0.0647808155833058,
           0.0011872161692842004
          ],
          [
           -0.03806651717546608,
           0.11715175357571722,
           0.04813652032609368,
           -0.026390840313729638,
           1,
           -0.0005435256044111326,
           -0.02440571448675496,
           0.04442859609511936,
           -0.0002919022347725365,
           -0.004293914031042557,
           -0.032111781953265466,
           -0.022649241864517868,
           0.10334818495737665,
           0.7097114024681394,
           0.019490412851459187,
           0.13203415204855268,
           0.05561577625017708,
           0.07427554427056277,
           -0.06159029395603711,
           0.02476553942255994,
           -0.02601252501550376,
           -0.034981854121457566,
           -0.005368870632992556,
           -0.06799844563516085,
           -0.03605750398739883,
           0.08203321116407217,
           0.019549375218363592,
           -0.025446321326017807,
           -0.027777687204148697,
           -0.03060045552677263,
           -0.0039056557943246634
          ],
          [
           -0.016469064720937936,
           0.04433116904442103,
           -0.06870642998948455,
           -0.06434958764064853,
           -0.0005435256044111326,
           1,
           0.040353921601135385,
           -0.025258784750652602,
           0.0009783877934453227,
           0.03098461366178496,
           -0.016427756241866584,
           0.03866009949726402,
           0.01826706921890377,
           -0.057785805664840345,
           -0.022030883111779212,
           -0.04298690935181735,
           -0.01861429801270532,
           0.01430509674978227,
           -0.08957738064878372,
           0.05272491517267452,
           0.08355041126965693,
           0.06091535533079987,
           0.013160204666215898,
           0.04995447039210544,
           -0.020351949915179503,
           -0.07209873193595022,
           -0.01877175145458371,
           0.009586323281567902,
           -0.003932099465489743,
           -0.010624726362504906,
           0.02101294557866695
          ],
          [
           0.2044419982891652,
           -0.0469140646953918,
           0.015570880761258492,
           -0.03172780775432659,
           -0.02440571448675496,
           0.040353921601135385,
           1,
           -0.06297940206416763,
           -0.000632751530147202,
           0.052009491866199006,
           0.020068777740459464,
           0.05141782524950026,
           0.08148414011749613,
           -0.002556520868333933,
           0.009564548088547538,
           -0.0636374623743712,
           0.06852872931364658,
           0.0069606385585881635,
           0.11244675926777976,
           0.014050720823056586,
           0.0012121517708679186,
           -0.01543813281695508,
           0.014438774740415179,
           0.05432759946655546,
           0.12859027015065297,
           -0.07197786854700872,
           -0.06801017147088399,
           0.08556770944741007,
           0.0758532097566153,
           0.046101514622664895,
           0.09254923343036259
          ],
          [
           -0.0684602777783119,
           0.003045286684944241,
           0.028060074799952133,
           0.06306214651205079,
           0.04442859609511936,
           -0.025258784750652602,
           -0.06297940206416763,
           1,
           0.07031060306693336,
           -0.003809939820824841,
           0.010198151124831434,
           0.01763759277728415,
           -0.04064266381368626,
           0.00151436799222683,
           -0.02123728498174283,
           -0.004656011121123519,
           -0.03479871428409712,
           -0.054185051244143606,
           -0.008588565795030393,
           -0.04737086871189832,
           -0.02018444014295509,
           -0.04153232238727304,
           -0.006523363333217283,
           -0.009099361588875265,
           -0.028584653803075157,
           0.011976319111303233,
           0.05798840423660057,
           0.024994337196997854,
           0.03568167249944284,
           0.013852085386610315,
           0.05364448156225171
          ],
          [
           0.03777333891641263,
           -0.13454959227330665,
           -0.04200371761639541,
           0.041552659307872455,
           -0.0002919022347725365,
           0.0009783877934453227,
           -0.000632751530147202,
           0.07031060306693336,
           1,
           0.04735814656643153,
           -0.015022314395679904,
           0.003057323138973492,
           0.016724455281456545,
           0.014148026846454892,
           0.05053206160648543,
           0.02504511475380635,
           0.006436450690495987,
           -0.015899707914530683,
           -0.12014761682500522,
           0.018757982420908755,
           0.02193635493462075,
           -0.008950975869735367,
           0.011186763383480812,
           -0.017026572830517006,
           0.004068910761846506,
           0.019625149940440165,
           -0.06846482949181097,
           0.07075232561367667,
           0.06380006912768216,
           0.06915663233261492,
           0.06431466392060425
          ],
          [
           0.008410390861334629,
           0.043290448929478004,
           -0.009786465788189768,
           0.06987144182724432,
           -0.004293914031042557,
           0.03098461366178496,
           0.052009491866199006,
           -0.003809939820824841,
           0.04735814656643153,
           1,
           -0.0023618404087726004,
           -0.04737425032065634,
           -0.02639340793670555,
           -0.003251104785963898,
           0.005031664207775302,
           -0.041225541056448975,
           -0.02587500348270274,
           -0.07622564328316958,
           0.04574073019320355,
           0.0057838322209246935,
           0.03629326741841581,
           -0.01725312578396493,
           0.051273056182626515,
           -0.002039054198786171,
           -0.014260032563598715,
           -0.004932478278904328,
           -0.08676082237504422,
           -0.07429500484912835,
           -0.09406497991813817,
           -0.03934690396218625,
           -0.06422767023022947
          ],
          [
           0.04537729655255323,
           -0.05065797408870541,
           -0.03063419804995875,
           0.056177158641713174,
           -0.032111781953265466,
           -0.016427756241866584,
           0.020068777740459464,
           0.010198151124831434,
           -0.015022314395679904,
           -0.0023618404087726004,
           1,
           0.0446184979431396,
           -0.004633261104921616,
           -0.023671587785400208,
           -0.06801698519940404,
           0.01431453310161111,
           0.00843693293402323,
           -0.03280333798927252,
           -0.0297755615795749,
           0.023103656569094137,
           -0.035080284167392256,
           -0.054009428541341165,
           0.020763623053284993,
           0.044685910387948634,
           -0.0021485418014124532,
           -0.011861988865341221,
           -0.04370133914924095,
           -0.010579236183056043,
           0.008881108962470515,
           -0.05629124145106893,
           0.04442957983208551
          ],
          [
           0.022039749856737696,
           -0.16962191386981917,
           0.03783524187493622,
           0.010510257411369451,
           -0.022649241864517868,
           0.03866009949726402,
           0.05141782524950026,
           0.01763759277728415,
           0.003057323138973492,
           -0.04737425032065634,
           0.0446184979431396,
           1,
           -0.03694631735096855,
           -0.003331798081619596,
           -0.03444862855322519,
           -0.05449703736822999,
           -0.03553492446928529,
           0.05995778998810842,
           -0.027672889014524155,
           0.021029399305175403,
           0.00038540317469170867,
           -0.04651493555274987,
           0.05231815941306964,
           0.06273998704961699,
           -0.034261615183129646,
           -0.03928939973202353,
           0.01851818078516179,
           -0.013352247039787416,
           0.01342843573467995,
           -0.043995148184055095,
           0.03478604804639279
          ],
          [
           0.5322984512316848,
           -0.232837481527023,
           0.014936329451371563,
           -0.0029189596389754225,
           0.10334818495737665,
           0.01826706921890377,
           0.08148414011749613,
           -0.04064266381368626,
           0.016724455281456545,
           -0.02639340793670555,
           -0.004633261104921616,
           -0.03694631735096855,
           1,
           -0.06833777959352315,
           0.06025471317354887,
           -0.13666967966278823,
           0.9519719229979409,
           0.011228807864293394,
           0.08580747726756682,
           -0.08709852940556342,
           -0.06361327851199353,
           -0.06567465710979863,
           0.013850359507830113,
           0.10671843581081987,
           0.7915553795412157,
           -0.03960535529192612,
           0.05488151048389738,
           0.597942308035613,
           0.5043225004251465,
           0.3602007249647148,
           0.42952077037985387
          ],
          [
           -0.11752311959271518,
           0.08626330313866695,
           -0.00494677352876189,
           -0.01441525750125425,
           0.7097114024681394,
           -0.057785805664840345,
           -0.002556520868333933,
           0.00151436799222683,
           0.014148026846454892,
           -0.003251104785963898,
           -0.023671587785400208,
           -0.003331798081619596,
           -0.06833777959352315,
           1,
           0.0005974987357388515,
           0.1392935862467999,
           -0.0791330134014474,
           0.061985877504297446,
           -0.04240030809275578,
           0.08714360950023954,
           0.01964578435768572,
           -0.016945550093179405,
           -0.048291445017728155,
           -0.07205118639534065,
           -0.13205782660200666,
           0.021405592928177723,
           0.07236527200136103,
           -0.09520633457215857,
           -0.0830974434740552,
           -0.07409932522685216,
           -0.04481484087260792
          ],
          [
           0.04511002353614836,
           -0.142439159423648,
           -0.01622021619690571,
           0.05424600463374355,
           0.019490412851459187,
           -0.022030883111779212,
           0.009564548088547538,
           -0.02123728498174283,
           0.05053206160648543,
           0.005031664207775302,
           -0.06801698519940404,
           -0.03444862855322519,
           0.06025471317354887,
           0.0005974987357388515,
           1,
           -0.026929881055944776,
           0.047719172407970654,
           0.09825264198026512,
           -0.03421207422454596,
           -0.02748318498030249,
           -0.08379708144272122,
           -0.06777463033113637,
           -0.001542250405526535,
           0.06976095458234542,
           0.026112523329765363,
           -0.03757986837745633,
           -0.010234901298030513,
           0.08109385867920009,
           0.09732887383070953,
           0.04879052712846037,
           0.016128614446798906
          ],
          [
           -0.1796546221127244,
           0.23589109199350203,
           -0.014968621910563445,
           -0.0825626698809224,
           0.13203415204855268,
           -0.04298690935181735,
           -0.0636374623743712,
           -0.004656011121123519,
           0.02504511475380635,
           -0.041225541056448975,
           0.01431453310161111,
           -0.05449703736822999,
           -0.13666967966278823,
           0.1392935862467999,
           -0.026929881055944776,
           1,
           -0.1318894825624846,
           -0.010168456567787438,
           -0.12721935829552736,
           0.049646879046305305,
           0.04496922146390679,
           0.050898340136578284,
           -0.06072185411180057,
           -0.6688600377461675,
           -0.14004541278646399,
           0.05896819834975349,
           0.0011315641897721935,
           -0.07524525415325306,
           -0.08597926159156072,
           -0.004106491319870095,
           -0.04843818518819617
          ],
          [
           0.5230386923179968,
           -0.24199396283578986,
           0.019375275256735807,
           -0.0017055486996842356,
           0.05561577625017708,
           -0.01861429801270532,
           0.06852872931364658,
           -0.03479871428409712,
           0.006436450690495987,
           -0.02587500348270274,
           0.00843693293402323,
           -0.03553492446928529,
           0.9519719229979409,
           -0.0791330134014474,
           0.047719172407970654,
           -0.1318894825624846,
           1,
           0.002648556591727287,
           0.09393736961293127,
           -0.06802728039307389,
           -0.06859426786932167,
           -0.0810449477658772,
           0.02262377932914488,
           0.0892542700224295,
           0.7785219162065224,
           -0.0615484140813255,
           0.04382013300574155,
           0.5815328381588276,
           0.4817107607270371,
           0.35124798189789413,
           0.39632235543982225
          ],
          [
           -0.01189901969177255,
           -0.0011713135674544062,
           0.0504525279898948,
           -0.09250082055470663,
           0.07427554427056277,
           0.01430509674978227,
           0.0069606385585881635,
           -0.054185051244143606,
           -0.015899707914530683,
           -0.07622564328316958,
           -0.03280333798927252,
           0.05995778998810842,
           0.011228807864293394,
           0.061985877504297446,
           0.09825264198026512,
           -0.010168456567787438,
           0.002648556591727287,
           1,
           0.04047051188692816,
           -0.0072165568137038194,
           -0.032892629831283465,
           -0.029527560627724943,
           -0.0073887809836945696,
           -0.06474980895175318,
           -0.012632113813429557,
           -0.07846078289430944,
           0.005185721479904525,
           -0.09171692589109427,
           -0.04675878876656127,
           -0.05193733133039235,
           -0.07856726631033167
          ],
          [
           0.2924628932163223,
           0.05904631295517528,
           -0.0032244626029381417,
           0.062102242598865834,
           -0.06159029395603711,
           -0.08957738064878372,
           0.11244675926777976,
           -0.008588565795030393,
           -0.12014761682500522,
           0.04574073019320355,
           -0.0297755615795749,
           -0.027672889014524155,
           0.08580747726756682,
           -0.04240030809275578,
           -0.03421207422454596,
           -0.12721935829552736,
           0.09393736961293127,
           0.04047051188692816,
           1,
           -0.0330553963562762,
           -0.05312419591611766,
           -0.05466333914468201,
           0.06229984086597678,
           0.0882276986711742,
           0.21705817301624705,
           -0.07339844598426919,
           -0.07581544145688189,
           -0.10894994780957593,
           -0.08996783402275223,
           -0.05412342890564707,
           -0.12549783916743343
          ],
          [
           -0.03266906341267767,
           0.3123240133693072,
           0.0042709534102400165,
           -0.012739511447619237,
           0.02476553942255994,
           0.05272491517267452,
           0.014050720823056586,
           -0.04737086871189832,
           0.018757982420908755,
           0.0057838322209246935,
           0.023103656569094137,
           0.021029399305175403,
           -0.08709852940556342,
           0.08714360950023954,
           -0.02748318498030249,
           0.049646879046305305,
           -0.06802728039307389,
           -0.0072165568137038194,
           -0.0330553963562762,
           1,
           0.04157396408449754,
           0.07089728503559078,
           0.03409374725250599,
           -0.061359663566201865,
           -0.0753472190650742,
           -0.09364645337712019,
           0.002613727097016434,
           -0.09866014403828836,
           -0.08942062381060743,
           -0.03186234306222363,
           -0.0797807552614407
          ],
          [
           -0.00501198695271921,
           0.021308386316823313,
           -0.08163817373831926,
           0.03738990701893371,
           -0.02601252501550376,
           0.08355041126965693,
           0.0012121517708679186,
           -0.02018444014295509,
           0.02193635493462075,
           0.03629326741841581,
           -0.035080284167392256,
           0.00038540317469170867,
           -0.06361327851199353,
           0.01964578435768572,
           -0.08379708144272122,
           0.04496922146390679,
           -0.06859426786932167,
           -0.032892629831283465,
           -0.05312419591611766,
           0.04157396408449754,
           1,
           0.7772505543664977,
           -0.061044527557406525,
           -0.019376241812806005,
           -0.06307652914928633,
           0.05601323973402391,
           0.05436994030788941,
           -0.06364050669818612,
           -0.03759035216397015,
           -0.02237030923600477,
           0.0024185516379588187
          ],
          [
           -0.016725290342173127,
           0.048751494941808644,
           -0.05210510166480561,
           0.03556294073747078,
           -0.034981854121457566,
           0.06091535533079987,
           -0.01543813281695508,
           -0.04153232238727304,
           -0.008950975869735367,
           -0.01725312578396493,
           -0.054009428541341165,
           -0.04651493555274987,
           -0.06567465710979863,
           -0.016945550093179405,
           -0.06777463033113637,
           0.050898340136578284,
           -0.0810449477658772,
           -0.029527560627724943,
           -0.05466333914468201,
           0.07089728503559078,
           0.7772505543664977,
           1,
           -0.019224881194968596,
           -0.06521073020672863,
           -0.04258305907692081,
           0.01502702556980143,
           0.07041722225209525,
           -0.03792911717355019,
           0.003045060088686911,
           0.015152067534286955,
           0.04384574151906142
          ],
          [
           0.06578397552974694,
           -0.06815829906213401,
           0.007713571801843202,
           0.005413137931607168,
           -0.005368870632992556,
           0.013160204666215898,
           0.014438774740415179,
           -0.006523363333217283,
           0.011186763383480812,
           0.051273056182626515,
           0.020763623053284993,
           0.05231815941306964,
           0.013850359507830113,
           -0.048291445017728155,
           -0.001542250405526535,
           -0.06072185411180057,
           0.02262377932914488,
           -0.0073887809836945696,
           0.06229984086597678,
           0.03409374725250599,
           -0.061044527557406525,
           -0.019224881194968596,
           1,
           0.020050495979239115,
           0.019918741193341815,
           0.06433302109686877,
           -0.022919258761065254,
           0.04471413571032563,
           0.03059645271667245,
           0.04073182253291686,
           -0.0005763536513962744
          ],
          [
           0.10781438397348501,
           -0.21833605451141255,
           -0.004171316322419631,
           0.04212814745651885,
           -0.06799844563516085,
           0.04995447039210544,
           0.05432759946655546,
           -0.009099361588875265,
           -0.017026572830517006,
           -0.002039054198786171,
           0.044685910387948634,
           0.06273998704961699,
           0.10671843581081987,
           -0.07205118639534065,
           0.06976095458234542,
           -0.6688600377461675,
           0.0892542700224295,
           -0.06474980895175318,
           0.0882276986711742,
           -0.061359663566201865,
           -0.019376241812806005,
           -0.06521073020672863,
           0.020050495979239115,
           1,
           0.07318867667317155,
           -0.012197114351871504,
           0.08786100150480702,
           0.0547588790611003,
           0.06826122001141172,
           0.01707100873711686,
           0.06011606876048638
          ],
          [
           0.7021340905512334,
           -0.2332490387774205,
           0.0757216517772843,
           0.011359357911573715,
           -0.03605750398739883,
           -0.020351949915179503,
           0.12859027015065297,
           -0.028584653803075157,
           0.004068910761846506,
           -0.014260032563598715,
           -0.0021485418014124532,
           -0.034261615183129646,
           0.7915553795412157,
           -0.13205782660200666,
           0.026112523329765363,
           -0.14004541278646399,
           0.7785219162065224,
           -0.012632113813429557,
           0.21705817301624705,
           -0.0753472190650742,
           -0.06307652914928633,
           -0.04258305907692081,
           0.019918741193341815,
           0.07318867667317155,
           1,
           -0.04139791945656068,
           0.005971328557280056,
           0.6709155060410702,
           0.5393918273453416,
           0.3805224725833096,
           0.46281252066756057
          ],
          [
           -0.0485655975527119,
           -0.02004794966598787,
           -0.002543108826553894,
           0.035564598985338806,
           0.08203321116407217,
           -0.07209873193595022,
           -0.07197786854700872,
           0.011976319111303233,
           0.019625149940440165,
           -0.004932478278904328,
           -0.011861988865341221,
           -0.03928939973202353,
           -0.03960535529192612,
           0.021405592928177723,
           -0.03757986837745633,
           0.05896819834975349,
           -0.0615484140813255,
           -0.07846078289430944,
           -0.07339844598426919,
           -0.09364645337712019,
           0.05601323973402391,
           0.01502702556980143,
           0.06433302109686877,
           -0.012197114351871504,
           -0.04139791945656068,
           1,
           0.05144235065868267,
           0.020631657184769666,
           -0.014859194284035749,
           -0.03457454309950214,
           0.01215038733657383
          ],
          [
           -0.03742701591139105,
           -0.07883727744668335,
           -0.07647276881744339,
           0.01841228413300356,
           0.019549375218363592,
           -0.01877175145458371,
           -0.06801017147088399,
           0.05798840423660057,
           -0.06846482949181097,
           -0.08676082237504422,
           -0.04370133914924095,
           0.01851818078516179,
           0.05488151048389738,
           0.07236527200136103,
           -0.010234901298030513,
           0.0011315641897721935,
           0.04382013300574155,
           0.005185721479904525,
           -0.07581544145688189,
           0.002613727097016434,
           0.05436994030788941,
           0.07041722225209525,
           -0.022919258761065254,
           0.08786100150480702,
           0.005971328557280056,
           0.05144235065868267,
           1,
           0.02200280002874288,
           0.1119179115289984,
           0.0009710278805125232,
           0.03788374435579437
          ],
          [
           0.36803256818109764,
           -0.181406910198046,
           0.031390250598443,
           -0.046810228089188465,
           -0.025446321326017807,
           0.009586323281567902,
           0.08556770944741007,
           0.024994337196997854,
           0.07075232561367667,
           -0.07429500484912835,
           -0.010579236183056043,
           -0.013352247039787416,
           0.597942308035613,
           -0.09520633457215857,
           0.08109385867920009,
           -0.07524525415325306,
           0.5815328381588276,
           -0.09171692589109427,
           -0.10894994780957593,
           -0.09866014403828836,
           -0.06364050669818612,
           -0.03792911717355019,
           0.04471413571032563,
           0.0547588790611003,
           0.6709155060410702,
           0.020631657184769666,
           0.02200280002874288,
           1,
           0.7967634975798056,
           0.5940413226410606,
           0.7484507799497827
          ],
          [
           0.3006448161331995,
           -0.24926103703267977,
           0.0015768677678572667,
           -0.019567712399833858,
           -0.027777687204148697,
           -0.003932099465489743,
           0.0758532097566153,
           0.03568167249944284,
           0.06380006912768216,
           -0.09406497991813817,
           0.008881108962470515,
           0.01342843573467995,
           0.5043225004251465,
           -0.0830974434740552,
           0.09732887383070953,
           -0.08597926159156072,
           0.4817107607270371,
           -0.04675878876656127,
           -0.08996783402275223,
           -0.08942062381060743,
           -0.03759035216397015,
           0.003045060088686911,
           0.03059645271667245,
           0.06826122001141172,
           0.5393918273453416,
           -0.014859194284035749,
           0.1119179115289984,
           0.7967634975798056,
           1,
           0.5823863414071675,
           0.7595135574683772
          ],
          [
           0.2107948083228227,
           -0.04032779066765742,
           -0.003949884492561511,
           -0.0647808155833058,
           -0.03060045552677263,
           -0.010624726362504906,
           0.046101514622664895,
           0.013852085386610315,
           0.06915663233261492,
           -0.03934690396218625,
           -0.05629124145106893,
           -0.043995148184055095,
           0.3602007249647148,
           -0.07409932522685216,
           0.04879052712846037,
           -0.004106491319870095,
           0.35124798189789413,
           -0.05193733133039235,
           -0.05412342890564707,
           -0.03186234306222363,
           -0.02237030923600477,
           0.015152067534286955,
           0.04073182253291686,
           0.01707100873711686,
           0.3805224725833096,
           -0.03457454309950214,
           0.0009710278805125232,
           0.5940413226410606,
           0.5823863414071675,
           1,
           0.5632748491102223
          ],
          [
           0.2402234444760164,
           -0.21049137680688512,
           0.009849971767811957,
           0.0011872161692842004,
           -0.0039056557943246634,
           0.02101294557866695,
           0.09254923343036259,
           0.05364448156225171,
           0.06431466392060425,
           -0.06422767023022947,
           0.04442957983208551,
           0.03478604804639279,
           0.42952077037985387,
           -0.04481484087260792,
           0.016128614446798906,
           -0.04843818518819617,
           0.39632235543982225,
           -0.07856726631033167,
           -0.12549783916743343,
           -0.0797807552614407,
           0.0024185516379588187,
           0.04384574151906142,
           -0.0005763536513962744,
           0.06011606876048638,
           0.46281252066756057,
           0.01215038733657383,
           0.03788374435579437,
           0.7484507799497827,
           0.7595135574683772,
           0.5632748491102223,
           1
          ]
         ]
        }
       ],
       "layout": {
        "height": 700,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pearson Correlation of numerical features"
        },
        "width": 900,
        "xaxis": {
         "nticks": 31,
         "ticks": ""
        },
        "yaxis": {
         "ticks": ""
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the correlation between target and other columns\n",
    "def correlation_heatmap(df):\n",
    "    columns = df.columns\n",
    "    data = [go.Heatmap(z=df[columns].corr().values,\n",
    "              x=df[columns].columns.values,\n",
    "              y=df[columns].columns.values,\n",
    "              colorscale=\"Viridis\",\n",
    "              reversescale=False,\n",
    "              opacity=1.0)]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Pearson Correlation of numerical features',\n",
    "        xaxis = dict(ticks='', nticks=len(columns)),\n",
    "        yaxis = dict(ticks='' ),\n",
    "        width = 900, height = 700,\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='labelled-heatmap')\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[_target_column]\n",
    "X = df.drop(_target_column, axis=1)\n",
    "\n",
    "# split dataset\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "train_labels.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train data: 379\n",
      "Number of rows in test data: 95\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in train data: {len(train_data)}\")\n",
    "print(f\"Number of rows in test data: {len(test_data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune_logistic_regression(search_space,max_iterations,training_data,training_labels,kfolds=5):\n",
    "    print(\"Tuning Hyper-parameter for Logistic Regression\")\n",
    "    def objective(search_space):\n",
    "        model = LogisticRegression(**search_space)\n",
    "        cv_results = cross_val_score(model, X=training_data, y=training_labels, cv=kfolds,scoring=\"accuracy\")\n",
    "        accuracy = cv_results.mean()    \n",
    "        return {\"loss\":(1-accuracy),\"status\":STATUS_OK}\n",
    "    \n",
    "    best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=max_iterations)    \n",
    "    print(\"Tuning completed\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyper-parameter for Logistic Regression\n",
      "  1%|          | 1/120 [00:00<00:39,  3.01trial/s, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|         | 2/120 [00:04<05:12,  2.65s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|         | 3/120 [00:05<04:01,  2.06s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|         | 4/120 [00:06<03:09,  1.63s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|         | 5/120 [00:07<02:43,  1.42s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|         | 6/120 [00:10<03:13,  1.70s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|         | 7/120 [00:14<04:35,  2.44s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|         | 8/120 [00:15<03:59,  2.14s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|         | 10/120 [00:16<02:02,  1.12s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|         | 12/120 [00:19<02:16,  1.27s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|         | 13/120 [00:23<03:53,  2.18s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|        | 14/120 [00:25<03:32,  2.01s/trial, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|        | 18/120 [00:26<01:04,  1.59trial/s, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|        | 19/120 [00:27<01:28,  1.14trial/s, best loss: 0.28268756998880185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|        | 23/120 [00:28<00:38,  2.49trial/s, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|        | 24/120 [00:29<00:54,  1.76trial/s, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|       | 27/120 [00:30<00:35,  2.59trial/s, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|       | 28/120 [00:33<01:50,  1.20s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|       | 29/120 [00:40<04:37,  3.05s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|       | 31/120 [00:41<02:31,  1.70s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|       | 32/120 [00:41<01:49,  1.24s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|       | 33/120 [00:46<03:07,  2.15s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|       | 34/120 [00:46<02:27,  1.72s/trial, best loss: 0.28266517357222853]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|       | 36/120 [00:48<01:44,  1.25s/trial, best loss: 0.280582306830907]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|       | 37/120 [00:50<02:00,  1.46s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|      | 38/120 [00:50<01:30,  1.10s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|      | 39/120 [00:51<01:20,  1.01trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|      | 41/120 [00:56<02:18,  1.75s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|      | 42/120 [00:56<01:45,  1.35s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|      | 44/120 [00:56<01:01,  1.24trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|      | 45/120 [00:58<01:05,  1.15trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|      | 47/120 [01:02<01:39,  1.36s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|      | 48/120 [01:04<02:02,  1.70s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|      | 49/120 [01:05<01:45,  1.48s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|     | 51/120 [01:06<01:01,  1.12trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|     | 52/120 [01:08<01:27,  1.29s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|     | 53/120 [01:08<01:05,  1.02trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|     | 55/120 [01:12<01:27,  1.34s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|     | 56/120 [01:17<02:30,  2.36s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|     | 57/120 [01:19<02:22,  2.27s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|     | 59/120 [01:20<01:14,  1.22s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|     | 60/120 [01:21<01:21,  1.36s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|     | 61/120 [01:22<01:00,  1.03s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|    | 63/120 [01:26<01:20,  1.41s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|    | 64/120 [01:29<01:49,  1.95s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|    | 72/120 [01:31<00:16,  2.86trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|    | 73/120 [01:32<00:24,  1.93trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|   | 74/120 [01:32<00:20,  2.23trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|   | 75/120 [01:33<00:19,  2.32trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|   | 76/120 [01:33<00:16,  2.67trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|   | 77/120 [01:36<00:55,  1.29s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|   | 78/120 [01:37<00:46,  1.11s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|   | 79/120 [01:37<00:34,  1.20trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|   | 80/120 [01:38<00:28,  1.38trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|   | 83/120 [01:38<00:15,  2.41trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|   | 85/120 [01:43<00:53,  1.53s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|  | 86/120 [01:45<00:53,  1.58s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|  | 88/120 [01:45<00:29,  1.07trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|  | 89/120 [01:47<00:41,  1.33s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|  | 91/120 [01:50<00:35,  1.21s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|  | 93/120 [01:54<00:48,  1.81s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|  | 94/120 [01:56<00:46,  1.77s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|  | 96/120 [01:58<00:29,  1.25s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%| | 98/120 [01:58<00:15,  1.38trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%| | 100/120 [02:01<00:25,  1.26s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%| | 101/120 [02:01<00:17,  1.06trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%| | 102/120 [02:02<00:17,  1.03trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%| | 104/120 [02:03<00:09,  1.65trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%| | 105/120 [02:03<00:07,  2.05trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%| | 106/120 [02:03<00:06,  2.07trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%| | 107/120 [02:04<00:05,  2.53trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%| | 109/120 [02:08<00:11,  1.02s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|| 110/120 [02:10<00:15,  1.53s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|| 111/120 [02:11<00:10,  1.16s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|| 112/120 [02:11<00:07,  1.09trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|| 113/120 [02:11<00:04,  1.41trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|| 114/120 [02:12<00:05,  1.10trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|| 116/120 [02:13<00:02,  1.90trial/s, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning:\n",
      "\n",
      "The line search algorithm did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|| 117/120 [02:15<00:03,  1.01s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%|| 119/120 [02:17<00:01,  1.04s/trial, best loss: 0.280582306830907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n",
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 120/120 [02:19<00:00,  1.16s/trial, best loss: 0.280582306830907]\n",
      "Tuning completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muhammad.tayyab01\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define search space for Logistic Regression model.\n",
    "search_space = {\n",
    "    \"solver\": hp.choice(\"solver\",['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']),\n",
    "    \"C\": hp.quniform(\"C\",1,30,2),\n",
    "    \"max_iter\": hp.quniform(\"max_iter\",100,1000,100)\n",
    "    }\n",
    "best_params = tune_logistic_regression(search_space=search_space, max_iterations=120,training_data=X,training_labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 6.0, 'max_iter': 100.0, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuned Hyperparameters\n",
    "best_parameters = space_eval(search_space, best_params)\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on tuned hyperparameters\n",
    "lr = LogisticRegression(**best_parameters)\n",
    "lr.fit(train_data, train_labels)\n",
    "y_pred = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(test_labels,predict_labels):\n",
    "    y_predict = predict_labels\n",
    "    cm = confusion_matrix(test_labels, y_predict)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    print(classification_report(test_labels, y_predict))\n",
    "    print(f\"Total accuracy: {accuracy_score(test_labels, y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.73        44\n",
      "           1       0.80      0.65      0.72        51\n",
      "\n",
      "    accuracy                           0.73        95\n",
      "   macro avg       0.74      0.73      0.73        95\n",
      "weighted avg       0.74      0.73      0.73        95\n",
      "\n",
      "Total accuracy: 0.7263157894736842\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(test_labels, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyper-Parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_random_forest(search_space,max_iterations, training_data, training_labels, kfolds=5):\n",
    "    print(\"Tuning Hyper-parameter for Random forest\")\n",
    "    def objective_(search_space):\n",
    "        model = RandomForestClassifier(**search_space)\n",
    "        cv_results = cross_val_score(model, X=training_data, y=training_labels, cv=kfolds,scoring=\"accuracy\")\n",
    "        accuracy = cv_results.mean()    \n",
    "        return {\"loss\":(1-accuracy),\"status\":STATUS_OK}\n",
    "    \n",
    "    best_params = fmin(fn=objective_, space=search_space, algo=tpe.suggest, max_evals=max_iterations)    \n",
    "    print(\"Hyper-parameter tuning is completed\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyper-parameter for Random forest\n",
      "100%|| 120/120 [11:52:01<00:00, 356.02s/trial, best loss: 0.24270996640537512]    \n",
      "Hyper-parameter tuning is completed\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"n_estimators\":hp.uniformint(\"n_estimators\",100,1000),\n",
    "    \"bootstrap\":hp.choice(\"bootstrap\",[True, False]),\n",
    "    \"max_depth\": hp.uniformint(\"max_depth\",10,100),\n",
    "    \"max_features\":hp.choice(\"max_features\",[\"sqrt\", \"log2\", None]),\n",
    "    \n",
    "}\n",
    "best_params = tune_random_forest(search_space=search_space, max_iterations=120, training_data=X, training_labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 59,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 410}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = space_eval(search_space, best_params)\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = RandomForestClassifier(**best_parameters)\n",
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       1.00      1.00      1.00        51\n",
      "\n",
      "    accuracy                           1.00        95\n",
      "   macro avg       1.00      1.00      1.00        95\n",
      "weighted avg       1.00      1.00      1.00        95\n",
      "\n",
      "Total accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(test_labels, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
